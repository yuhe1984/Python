{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import LabelBinarizer #标签二值化\n",
    "from sklearn.model_selection import train_test_split   #切割数据,交叉验证法\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(data,target):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()  \n",
    "    data = min_max_scaler.fit_transform(data)\n",
    "    label = zeros([150,3])\n",
    "    for i in range(150):\n",
    "        label[i][target[i]] = 1\n",
    "    return data,label\n",
    "\n",
    "def loadData():\n",
    "    iris = datasets.load_iris()\n",
    "    #n_samples,n_features=iris.data.shape\n",
    "    #print(\"Number of sample:\",n_samples)  \n",
    "    #print(\"Number of feature\",n_features)\n",
    "    data = iris.data\n",
    "    label = iris.target\n",
    "    data,label = normalization(data,label)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,label = loadData()\n",
    "\n",
    "train_data,test_data,train_label,test_label = train_test_split(data,label,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0,Testing Accuracy:0.23333333\n",
      "Iter50,Testing Accuracy:0.23333333\n",
      "Iter100,Testing Accuracy:0.23333333\n",
      "Iter150,Testing Accuracy:0.23333333\n",
      "Iter200,Testing Accuracy:0.23333333\n",
      "Iter250,Testing Accuracy:0.23333333\n",
      "Iter300,Testing Accuracy:0.23333333\n",
      "Iter350,Testing Accuracy:0.23333333\n",
      "Iter400,Testing Accuracy:0.23333333\n",
      "Iter450,Testing Accuracy:0.23333333\n",
      "Iter500,Testing Accuracy:0.23333333\n",
      "Iter550,Testing Accuracy:0.23333333\n",
      "Iter600,Testing Accuracy:0.23333333\n",
      "Iter650,Testing Accuracy:0.23333333\n",
      "Iter700,Testing Accuracy:0.23333333\n",
      "Iter750,Testing Accuracy:0.23333333\n",
      "Iter800,Testing Accuracy:0.23333333\n",
      "Iter850,Testing Accuracy:0.23333333\n",
      "Iter900,Testing Accuracy:0.23333333\n",
      "Iter950,Testing Accuracy:0.6666667\n",
      "Iter1000,Testing Accuracy:0.6666667\n",
      "Iter1050,Testing Accuracy:0.6666667\n",
      "Iter1100,Testing Accuracy:0.6666667\n",
      "Iter1150,Testing Accuracy:0.7\n",
      "Iter1200,Testing Accuracy:0.7\n",
      "Iter1250,Testing Accuracy:0.7\n",
      "Iter1300,Testing Accuracy:0.73333335\n",
      "Iter1350,Testing Accuracy:0.73333335\n",
      "Iter1400,Testing Accuracy:0.73333335\n",
      "Iter1450,Testing Accuracy:0.73333335\n",
      "Iter1500,Testing Accuracy:0.73333335\n",
      "Iter1550,Testing Accuracy:0.73333335\n",
      "Iter1600,Testing Accuracy:0.76666665\n",
      "Iter1650,Testing Accuracy:0.76666665\n",
      "Iter1700,Testing Accuracy:0.76666665\n",
      "Iter1750,Testing Accuracy:0.76666665\n",
      "Iter1800,Testing Accuracy:0.76666665\n",
      "Iter1850,Testing Accuracy:0.76666665\n",
      "Iter1900,Testing Accuracy:0.76666665\n",
      "Iter1950,Testing Accuracy:0.76666665\n",
      "Iter1999,Testing Accuracy:0.76666665\n"
     ]
    }
   ],
   "source": [
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,4])\n",
    "y = tf.placeholder(tf.float32,[None,3])\n",
    "\n",
    "hn = 10   #中间层神经元数量\n",
    "\n",
    "#定义神经网络中间层\n",
    "Weights_L1 = tf.Variable(tf.random_normal([4,10]))\n",
    "biases_L1 = tf.Variable(tf.zeros([1,10]))\n",
    "Wx_plus_b_L1 = tf.matmul(x,Weights_L1) + biases_L1\n",
    "L1 = tf.nn.sigmoid(Wx_plus_b_L1)\n",
    "\n",
    "#定义神经网络输出层\n",
    "Weights_L2 = tf.Variable(tf.random_normal([10,3]))\n",
    "biases_L2 = tf.Variable(tf.zeros([1,3]))\n",
    "Wx_plus_b_L2 = tf.matmul(L1,Weights_L2) + biases_L2\n",
    "prediction = tf.nn.sigmoid(Wx_plus_b_L2)\n",
    "\n",
    "#二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#交叉熵代价函数\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "\n",
    "#使用梯度下降法训练\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "tf.train.GradientDescentOptimizer\n",
    "\n",
    "#初始化设置\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmac返回一维张量中最大的值所在的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #变量初始化\n",
    "    sess.run(init)\n",
    "    for i in range(2000):\n",
    "        sess.run(train_step,feed_dict={x:train_data,y:train_label})\n",
    "            \n",
    "    #获得预测值\n",
    "    #prediction_value = sess.run(prediction,feed_dict={x:train_data})\n",
    "    #print(prediction_value)\n",
    "    \n",
    "    #求准确率\n",
    "        if i % 50 ==0:\n",
    "            acc = sess.run(accuracy,feed_dict={x:test_data,y:test_label})\n",
    "            print(\"Iter\"  + str(i) + \",Testing Accuracy:\" + str(acc))\n",
    "    print(\"Iter\"  + str(i) + \",Testing Accuracy:\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
